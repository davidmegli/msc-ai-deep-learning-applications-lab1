{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd7f5174",
   "metadata": {},
   "source": [
    "# 0. Initialization stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "116a044e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\verba\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] Impossibile trovare la procedura specificata'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Getting currend working directory -> Adding it to Path (to be able to import local modules)\n",
    "import os\n",
    "import sys\n",
    "# Getting parent directory of current working directory\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    # Adding parent directory to path\n",
    "    sys.path.append(nb_dir)\n",
    "\n",
    "# Importing local modules\n",
    "from utils import*\n",
    "from models import*\n",
    "from train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8876ad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "def run_command(command):\n",
    "    process = subprocess.Popen(command.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "    for line in iter(process.stdout.readline, b''):\n",
    "        print(line.decode().strip())\n",
    "    process.stdout.close()\n",
    "    process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea63959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/whl/cu121\n",
      "Collecting torch==2.5.0\n",
      "Using cached torch-2.5.0-cp310-cp310-win_amd64.whl (203.1 MB)\n",
      "Collecting torchvision\n",
      "Downloading torchvision-0.22.0-cp310-cp310-win_amd64.whl (1.7 MB)\n",
      "---------------------------------------- 1.7/1.7 MB 114.0 kB/s eta 0:00:00\n",
      "Collecting torchaudio\n",
      "Downloading torchaudio-2.7.0-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "---------------------------------------- 2.5/2.5 MB 115.6 kB/s eta 0:00:00\n",
      "Collecting sympy==1.13.1\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\verba\\anaconda3\\lib\\site-packages (from torch==2.5.0) (3.1.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\verba\\anaconda3\\lib\\site-packages (from torch==2.5.0) (2.8.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\verba\\anaconda3\\lib\\site-packages (from torch==2.5.0) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\verba\\anaconda3\\lib\\site-packages (from torch==2.5.0) (4.13.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\verba\\anaconda3\\lib\\site-packages (from torch==2.5.0) (3.14.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\verba\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch==2.5.0) (1.2.1)\n",
      "Collecting torchvision\n",
      "Using cached torchvision-0.21.0-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "Downloading torchvision-0.20.1-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "---------------------------------------- 1.6/1.6 MB 95.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\verba\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\verba\\anaconda3\\lib\\site-packages (from torchvision) (1.23.5)\n",
      "Downloading torchvision-0.20.0-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "---------------------------------------- 1.6/1.6 MB 158.2 kB/s eta 0:00:00\n",
      "Collecting torchaudio\n",
      "Downloading torchaudio-2.6.0-cp310-cp310-win_amd64.whl (2.4 MB)\n",
      "---------------------------------------- 2.4/2.4 MB 477.5 kB/s eta 0:00:00\n",
      "Downloading torchaudio-2.5.1-cp310-cp310-win_amd64.whl (2.4 MB)\n",
      "---------------------------------------- 2.4/2.4 MB 406.4 kB/s eta 0:00:00\n",
      "Downloading torchaudio-2.5.0-cp310-cp310-win_amd64.whl (2.4 MB)\n",
      "---------------------------------------- 2.4/2.4 MB 1.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\verba\\anaconda3\\lib\\site-packages (from jinja2->torch==2.5.0) (2.1.1)\n",
      "Installing collected packages: sympy, torch, torchvision, torchaudio\n",
      "Attempting uninstall: sympy\n",
      "Found existing installation: sympy 1.11.1\n",
      "Uninstalling sympy-1.11.1:\n",
      "Successfully uninstalled sympy-1.11.1\n",
      "Attempting uninstall: torch\n",
      "Found existing installation: torch 1.12.1\n",
      "Uninstalling torch-1.12.1:\n",
      "Successfully uninstalled torch-1.12.1\n",
      "Successfully installed sympy-1.13.1 torch-2.5.0 torchaudio-2.5.0 torchvision-0.20.0\n"
     ]
    }
   ],
   "source": [
    "run_command(\"pip uninstall torch torchvision torchaudio -y\")\n",
    "#run_command(\"pip install torch==2.5.0 torchvision torchaudio -f https://download.pytorch.org/whl/whl/cu121\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20bd9fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.9\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Thu_Sep_12_02:55:00_Pacific_Daylight_Time_2024\n",
      "Cuda compilation tools, release 12.6, V12.6.77\n",
      "Build cuda_12.6.r12.6/compiler.34841621_0\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75fa460e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 28 19:16:23 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 536.67                 Driver Version: 536.67       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3070 ...  WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   52C    P5              18W / 120W |   2378MiB /  8192MiB |     41%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      5116    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A      6276    C+G   ...ere Pro 2024\\Adobe Premiere Pro.exe    N/A      |\n",
      "|    0   N/A  N/A      9640    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A      9664    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10900    C+G   ..._x64__cw5n1h2txyewy\\WidgetBoard.exe    N/A      |\n",
      "|    0   N/A  N/A     11584    C+G   ...024\\CEPHtmlEngine\\CEPHtmlEngine.exe    N/A      |\n",
      "|    0   N/A  N/A     11852    C+G   ...on\\135.0.3179.98\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     16040    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     16648    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     19096    C+G   ...__8wekyb3d8bbwe\\Notepad\\Notepad.exe    N/A      |\n",
      "|    0   N/A  N/A     20800    C+G   ...ncoder 2024\\Adobe Media Encoder.exe    N/A      |\n",
      "|    0   N/A  N/A     23676    C+G   ...am Files (x86)\\VideoLAN\\VLC\\vlc.exe    N/A      |\n",
      "|    0   N/A  N/A     25352    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     26312    C+G   ...334.0_x64__dt26b99r8h8gj\\RtkUWP.exe    N/A      |\n",
      "|    0   N/A  N/A     31968    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     32200    C+G   ...3.0_x64__cv1g1gvanyjgm\\WhatsApp.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa612608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f2e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_losses(losses, title='Losses', xlabel='Epochs', ylabel='Loss'):\n",
    "    \"\"\"\n",
    "    Function to plot losses\n",
    "    :param losses: list of losses\n",
    "    :param title: title of the plot\n",
    "    :param xlabel: x-axis label\n",
    "    :param ylabel: y-axis label\n",
    "    \"\"\"\n",
    "    plt.plot(losses)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd55833",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISABLE_WANDB = True\n",
    "param_mlp_conf = 'configs/config_param_mlp'\n",
    "res_mlp_conf = 'configs/config_residual_mlp'\n",
    "dataset = '_mnist'\n",
    "depth = '_depth'\n",
    "ext = '.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac5f602",
   "metadata": {},
   "source": [
    "# 1.1 Baseline MLP\n",
    "Training the parametric MLP on MNIST with depth 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234e69f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 2\n",
    "conf = param_mlp_conf + dataset + str(depth) + ext\n",
    "t_losses, t_accs, v_losses, v_accs = train(config_file_path=conf, disable_wandb=DISABLE_WANDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af80dcbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24f7b8b6",
   "metadata": {},
   "source": [
    "Running training for ParametrizedMLP and ResidualMLP, for different depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f6278c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavidcopper\u001b[0m (\u001b[33mdavid_copper\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./runs\\wandb\\run-20250428_165217-350rly8u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/david_copper/ParametrizedMLP_MNIST/runs/350rly8u' target=\"_blank\">fancy-brook-12</a></strong> to <a href='https://wandb.ai/david_copper/ParametrizedMLP_MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/david_copper/ParametrizedMLP_MNIST' target=\"_blank\">https://wandb.ai/david_copper/ParametrizedMLP_MNIST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/david_copper/ParametrizedMLP_MNIST/runs/350rly8u' target=\"_blank\">https://wandb.ai/david_copper/ParametrizedMLP_MNIST/runs/350rly8u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.amp' has no attribute 'GradScaler'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m config_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfigs/config_param_mlp.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_file_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\verba\\Documents\\Projects\\msc-ai-deep-learning-applications-lab1\\train.py:59\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(config_file_path)\u001b[0m\n\u001b[0;32m     56\u001b[0m     wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproject_name\u001b[39m\u001b[38;5;124m'\u001b[39m], config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./runs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Initialize trainer\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput_dir\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpatience\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmixed_precision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmixed_precision\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproject_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_wandb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdefault_run\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresume\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m     78\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32mc:\\Users\\verba\\Documents\\Projects\\msc-ai-deep-learning-applications-lab1\\trainer.py:51\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, model, train_loader, val_loader, criterion, optimizer, scheduler, device, output_dir, max_epochs, patience, mixed_precision, project_name, use_wandb, run_name, resume)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_name \u001b[38;5;241m=\u001b[39m run_name\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume \u001b[38;5;241m=\u001b[39m resume\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mamp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGradScaler\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m,enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmixed_precision)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m SummaryWriter(log_dir\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# early stopping\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.amp' has no attribute 'GradScaler'"
     ]
    }
   ],
   "source": [
    "depths = [2, 5, 10, 20]\n",
    "param_mlp_confs = [param_mlp_conf + str(depth) + dataset + depth + ext for depth in depths]\n",
    "res_mlp_confs = [res_mlp_conf + str(depth) + dataset + depth + ext for depth in depths]\n",
    "for conf1, conf2 in zip(param_mlp_confs, res_mlp_confs):\n",
    "    train(config_file_path=conf1, disable_wandb=DISABLE_WANDB)\n",
    "    train(config_file_path=conf2, disable_wandb=DISABLE_WANDB)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
